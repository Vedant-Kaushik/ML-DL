{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33506e51-2288-474b-ae91-0d830f372b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045c811-35ce-4164-ab0e-fe21a03f92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b10e25-e1b2-4992-8b29-71a8ed4ea2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd716d-0dae-420b-884a-7f394184139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48da44f-2a97-4e15-afb5-37e638334e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99cf18-a096-4dc9-8a5e-4e2a3aa83ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts=['jpeg','png','jpg','bmp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bed53-1c1a-468f-9ed2-538574a567e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbb85f-97d2-4549-9c1d-075305bc0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5d4b5-fe19-4a9a-a597-8ca54c9df597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f23eb-94f2-44a5-8ab1-236a4ce2248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b08157-fa56-4aa8-8d3c-36959f5e9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_iterator=data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8d900-c3a3-4e8d-8dda-c3fba13cf23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=scaled_iterator.next()\n",
    "#class 1 =sad\n",
    "#class 0=happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe1971-0d57-4c9e-aca3-8bd10bf38dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 4 side-by-side subplots\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "\n",
    "# Initialize a counter variable\n",
    "idx = 0\n",
    "\n",
    "# Loop through the first 4 images in the batch\n",
    "for img in batch[0][:4]:\n",
    "    # Display each image in its respective subplot\n",
    "    ax[idx].imshow(img)\n",
    "    # Set the title of each subplot to the corresponding label\n",
    "    ax[idx].title.set_text(batch[1][idx])\n",
    "    # Increment the counter\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40245e5-4f06-41de-b66d-44c7c399c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=int(len(data)*.7)# batches \n",
    "cv_set=int(len(data)*.2)\n",
    "test_set=int(len(data)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b685cfb-9d21-48f3-a43f-e01d8a752f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_set)\n",
    "val = data.skip(train_set).take(cv_set)\n",
    "test = data.skip(train_set+cv_set).take(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1068ad-f14e-4867-8e78-8948d2c49712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e45a7-5e48-4e6e-a941-469ff0a35d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c6c5f-9671-470f-8d71-423d6151fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717abb7a-24cb-43f6-aa82-97ed5682e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449e66f-7e2b-4f1a-b9d8-59f2f7813cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d195e-da24-4541-8a38-9aec753526a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97ad6e-76b8-49df-8bc2-81794ef55675",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc820ff-8697-4c5a-ae65-5024b7d86b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908796c2-6b71-4c5b-b035-7b402f7d7882",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e0a041-d2c0-4407-82c9-220403c5ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87f7e0-ad62-4a36-adb5-995380016bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37176a-3991-4e20-b795-2f801a822634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb61ab-505e-40ae-968b-0f8bb55455d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85861921-c791-4d0e-8c55-60acdb9dbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('8iAb9k4aT.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb5b732-d1c0-45c0-b69f-f56d94982b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_img = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize_img.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ff1f2-9899-422b-b453-a144218fa5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize_img/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30768b31-4bf2-41ae-96d2-6bf22cf67641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9dd0fc-3cb7-45e4-a308-0dbb87f3c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','HappySadModel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b5f00-7a95-438f-b5be-092224165752",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(os.path.join('models','HappySadModel.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464afac-14e1-4c59-9c93-6e884b1621f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ynewhat = best_model.predict(np.expand_dims(resize_img/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02b68d-b3f6-467d-b800-bc09fbe47e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Sad')\n",
    "else:\n",
    "    print(f'Predicted class is Happy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872aa1b-5d05-4d2e-871f-3e4037e614f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
